[DATA]
corpora      =       europarl
lang        =       de
train       =       0
val         =       3000
test        =       3000
vocab          =       30000
tok             =   tok
reverse         =   True


[MODEL]
hid_dim     =       300
emb_dim     =       300
dropout     =       0.25
bidirectional   =   True
rnn             =   lstm
tied            =   True
attn            =   dot
beam            =   5
num_layers      =   2
pretrained      =   bert


[TRAINING]
epochs          =   240
batch_size      =   64
lr              =   0.0002
